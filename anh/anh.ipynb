{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import fasttext as ft\n",
    "from gensim.models import FastText, Word2Vec, KeyedVectors\n",
    "import MeCab as mc\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM, Embedding, Masking, GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Source</th>\n",
       "      <th>Metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>I'm feeling blue</td>\n",
       "      <td>I'm giving you a virtual hug right now.</td>\n",
       "      <td>qna_chitchat_the_friend</td>\n",
       "      <td>editorial:chitchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>I want to go shopping</td>\n",
       "      <td>I see.</td>\n",
       "      <td>qna_chitchat_the_friend</td>\n",
       "      <td>editorial:chitchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Hello!</td>\n",
       "      <td>qna_chitchat_the_friend</td>\n",
       "      <td>editorial:chitchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>I am tired</td>\n",
       "      <td>I've heard really good things about naps.</td>\n",
       "      <td>qna_chitchat_the_friend</td>\n",
       "      <td>editorial:chitchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>What is wrong with you!</td>\n",
       "      <td>I'm so sorry.</td>\n",
       "      <td>qna_chitchat_the_friend</td>\n",
       "      <td>editorial:chitchat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Question                                     Answer  \\\n",
       "579          I'm feeling blue    I'm giving you a virtual hug right now.   \n",
       "580     I want to go shopping                                     I see.   \n",
       "581                   Testing                                     Hello!   \n",
       "582                I am tired  I've heard really good things about naps.   \n",
       "583  What is wrong with you!                               I'm so sorry.   \n",
       "\n",
       "                      Source            Metadata  \n",
       "579  qna_chitchat_the_friend  editorial:chitchat  \n",
       "580  qna_chitchat_the_friend  editorial:chitchat  \n",
       "581  qna_chitchat_the_friend  editorial:chitchat  \n",
       "582  qna_chitchat_the_friend  editorial:chitchat  \n",
       "583  qna_chitchat_the_friend  editorial:chitchat  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load file Data_Intent.xlsx\n",
    "def data(path, is_tsv):\n",
    "    if is_tsv == True:\n",
    "        data = pd.read_table(path)\n",
    "    else:\n",
    "        data = pd.read_excel(path)\n",
    "    return data\n",
    "\n",
    "data = data('qna_chitchat_the_friend.tsv', True)\n",
    "# data.drop(data.index[487], inplace=True)\n",
    "# data = data.reset_index()\n",
    "# data.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "#split data into 2 part: test part with the first row of each intent and train part in other.\n",
    "def split_train_test(data, label_table):\n",
    "    \n",
    "    data_train = data_test = pd.DataFrame(columns=data.columns)\n",
    "    for i in label_table.unique():\n",
    "        if data[data['Answer']==i].shape[0]>=5:\n",
    "            train_ = data[label_table==i].iloc[1:, :]\n",
    "            test_ = data[label_table==i].iloc[:1, :]\n",
    "            data_train = pd.concat([data_train, train_], axis=0)\n",
    "            data_test = pd.concat([data_test, test_], axis=0)\n",
    "            data_train = data_train.reset_index(drop=True)\n",
    "            data_test = data_test.reset_index(drop=True)\n",
    "    return data_train, data_test\n",
    "\n",
    "data_train, data_test = split_train_test(data, data['Answer'])\n",
    "#Data0 is the merge of train parts and test parts\n",
    "data0 = pd.concat([data_train, data_test], axis=0)\n",
    "data0 = data0.reset_index(drop=True)\n",
    "data0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abbr_dict={\n",
    "    \"smarty-pants\":\"smart\",\n",
    "    \"Kthx\":\"thanks\",\n",
    "    \"kthx\":\"thanks\",\n",
    "    \"Thnx\":\"thanks\",\n",
    "    \"thnx\":\"thanks\",\n",
    "    \"bffs\":\"best friend\",\n",
    "    \n",
    "    \"what's\":\"what is\",\n",
    "    \"what're\":\"what are\",\n",
    "    \"who's\":\"who is\",\n",
    "    \"who're\":\"who are\",\n",
    "    \"where's\":\"where is\",\n",
    "    \"where're\":\"where are\",\n",
    "    \"when's\":\"when is\",\n",
    "    \"when're\":\"when are\",\n",
    "    \"how's\":\"how is\",\n",
    "    \"how're\":\"how are\",\n",
    "    \"you’re\":\"you are\",\n",
    "    \"that’s\": \"that is\",\n",
    "\n",
    "    \"i'm\":\"i am\",\n",
    "    \"I’m\": \"i am\",\n",
    "    \"i’m\": \"i am\",\n",
    "    \"we're\":\"we are\",\n",
    "    \"you're\":\"you are\",\n",
    "    \"they're\":\"they are\",\n",
    "    \"it's\":\"it is\",\n",
    "    \"he's\":\"he is\",\n",
    "    \"she's\":\"she is\",\n",
    "    \"that's\":\"that is\",\n",
    "    \"there's\":\"there is\",\n",
    "    \"there're\":\"there are\",\n",
    "\n",
    "    \"i've\":\"i have\",\n",
    "    \"we've\":\"we have\",\n",
    "    \"you've\":\"you have\",\n",
    "    \"they've\":\"they have\",\n",
    "    \"who've\":\"who have\",\n",
    "    \"would've\":\"would have\",\n",
    "    \"not've\":\"not have\",\n",
    "\n",
    "    \"i'll\":\"i will\",\n",
    "    \"we'll\":\"we will\",\n",
    "    \"you'll\":\"you will\",\n",
    "    \"he'll\":\"he will\",\n",
    "    \"she'll\":\"she will\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"they'll\":\"they will\",\n",
    "\n",
    "    \"isn't\":\"is not\",\n",
    "    \"wasn't\":\"was not\",\n",
    "    \"aren't\":\"are not\",\n",
    "    \"weren't\":\"were not\",\n",
    "    \"can't\":\"can not\",\n",
    "    \"couldn't\":\"could not\",\n",
    "    \"don't\":\"do not\",\n",
    "    \"didn't\":\"did not\",\n",
    "    \"shouldn't\":\"should not\",\n",
    "    \"wouldn't\":\"would not\",\n",
    "    \"doesn't\":\"does not\",\n",
    "    \"haven't\":\"have not\",\n",
    "    \"hasn't\":\"has not\",\n",
    "    \"hadn't\":\"had not\",\n",
    "    \"won't\":\"will not\",\n",
    "    \"nighty\": \"night\",\n",
    "    \"season's\":\"season is\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'giving', 'you', 'a', 'virtual', 'hug', 'right', 'now']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop word in japanese: load into Japanese.txt\n",
    "def stop_word(path, is_jap):\n",
    "    if is_jap == True:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        stopword = content.split('\\n')\n",
    "    else:\n",
    "        stopword = set(stopwords.words('english'))\n",
    "    return stopword   \n",
    "\n",
    "# split sentences into word and remove punc, stopword\n",
    "def split_text(str_, is_jap):\n",
    "    if is_jap == True:\n",
    "        str_ = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）：；《）《》“”()»〔〕-]+\", \"\",str_)\n",
    "        tag = mc.Tagger('-Ochasen')\n",
    "        kekka = tag.parse(str_)\n",
    "        lines = kekka.split('\\n')\n",
    "        word = []\n",
    "        for line in lines:\n",
    "            col = line.split('\\t')\n",
    "            if col[0] != None and col[0] != 'EOS' and col[0]!='':\n",
    "                if col[0] not in stopword:\n",
    "                    word.append(col[0])\n",
    "    else:\n",
    "        if str_ != '':\n",
    "            str_ = str_.lower()\n",
    "            for key, values in abbr_dict.items():\n",
    "                str_ = str_.replace(key, values)\n",
    "            \n",
    "            punc = list(string.punctuation)\n",
    "            stopword = stop_word('', False)\n",
    "            word = word_tokenize(str_)\n",
    "            word = [i for i in word if i not in punc]\n",
    "    return word\n",
    "\n",
    "split_text(\"I'm giving you a virtual hug right now\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['what', 'is', 'your', 'age']) list(['ask', 'me', 'anything'])\n",
      " list(['can', 'you', 'sleep']) list(['getting', 'tired', 'of', 'you'])\n",
      " list(['who', 'is', 'your', 'boss']) list(['cook', 'me', 'something'])\n",
      " list(['what', 'can', 'you', 'do']) list(['who', 'created', 'you'])\n",
      " list(['who', 'is', 'your', 'father']) list(['are', 'you', 'a', 'guy'])\n",
      " list(['how', 'happy', 'are', 'you'])\n",
      " list(['do', 'not', 'you', 'get', 'hungry'])\n",
      " list(['do', 'you', 'know', 'other', 'chatbots'])\n",
      " list(['what', 'is', 'your', 'favorite', 'color'])\n",
      " list(['what', 'is', 'your', 'name'])\n",
      " list(['what', 'do', 'you', 'think', 'about', 'love'])\n",
      " list(['what', 'do', 'you', 'think', 'about', 'ai'])\n",
      " list(['do', 'i', 'look', 'okay']) list(['what', 'should', 'i', 'do'])\n",
      " list(['what', 'do', 'you', 'think', 'about', 'cortana'])\n",
      " list(['do', 'you', 'want', 'to', 'rule', 'the', 'world'])\n",
      " list(['are', 'you', 'a', 'lesbian']) list(['you', 'are', 'a', 'genius'])\n",
      " list(['do', 'you', 'have', 'a', 'boyfriend']) list(['can', 'we', 'chat'])\n",
      " list(['can', 'you', 'say', 'anything', 'else'])\n",
      " list(['what', 'are', 'you']) list(['where', 'do', 'you', 'live'])\n",
      " list(['what', 'were', 'you', 'doing', 'yesterday'])\n",
      " list(['are', 'you', 'busy'])\n",
      " list(['you', 'can', 'not', 'work', 'for', 'me', 'anymore'])\n",
      " list(['tell', 'me', 'a', 'joke']) list(['tell', 'me', 'another', 'joke'])\n",
      " list(['say', 'something', 'funny']) list(['go', 'away'])\n",
      " list(['can', 'you', 'sing']) list(['you', 'are', 'awesome'])\n",
      " list(['you', 'are', 'dumb']) list(['that', 'is', 'not', 'funny'])\n",
      " list(['you', 'are', 'ugly'])\n",
      " list(['that', 'was', 'a', 'stupid', 'answer']) list(['awesome'])\n",
      " list(['ha']) list(['excuse', 'me']) list(['why', 'not'])\n",
      " list(['you', 'are', 'right']) list(['i', 'am', 'sorry'])\n",
      " list(['thank', 'you']) list(['you', 'made', 'no', 'sense'])\n",
      " list(['talk', 'to', 'you', 'later']) list(['hiya'])\n",
      " list(['good', 'night']) list(['how', 'are', 'you'])\n",
      " list(['hello', 'google']) list(['happy', 'halloween'])\n",
      " list(['what', 'is', 'up'])\n",
      " list(['i', 'think', 'you', 'are', 'so', 'pretty'])\n",
      " list(['be', 'my', 'friend']) list(['do', 'you', 'hate', 'me'])\n",
      " list(['do', 'you', 'know', 'me']) list(['i', 'like', 'you'])\n",
      " list(['i', 'love', 'you']) list(['will', 'you', 'marry', 'me'])\n",
      " list(['i', 'am', 'annoyed']) list(['i', 'am', 'bored'])\n",
      " list(['i', 'am', 'happy']) list(['i', 'am', 'hungry'])\n",
      " list(['i', 'am', 'doing', 'that']) list(['just', 'kidding'])\n",
      " list(['i', 'am', 'so', 'lonely']) list(['i', 'love', 'my', 'family'])\n",
      " list(['i', 'am', 'feeling', 'blue'])\n",
      " list(['i', 'want', 'to', 'go', 'shopping']) list(['testing'])\n",
      " list(['i', 'am', 'tired']) list(['what', 'is', 'wrong', 'with', 'you'])]\n"
     ]
    }
   ],
   "source": [
    "#transfer sample question into list of word for train, test data\n",
    "def transform_text(data):\n",
    "    question_transform = data.apply(lambda x: split_text(x, False))\n",
    "    return question_transform.values\n",
    "\n",
    "question_transform = transform_text(data0['Question'])\n",
    "question_transform_train = transform_text(data_train['Question'])\n",
    "question_transform_test = transform_text(data_test['Question'])\n",
    "\n",
    "\n",
    "print(question_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(path, limit):\n",
    "    model = KeyedVectors.load_word2vec_format(path, limit=limit)\n",
    "    return model\n",
    "\n",
    "fasttext = model('./pre_train/cc.en.300.vec', 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['report', 'full', 'pink', 'lol', 'anything', 'zip', 'haircut', 'other', 'that', 'stop', 'nobody', 'mom', 'marry', '1', 'name', 'born', 'agents', 'sisters', 'call', 'appreciate', 'long', 'songs', 'ready', 'sports', 'new', 'here', 'fake', 'owns', 'dreamy', 'anyone', 'we', 'more', 'for', 'which', 'what', 'pansexual', 'sorry', 'mean', 'digital', 'bored', 'testing', 'useless', 'meet', 'rad', 'father', 'eat', 'date', 'feeling', 'there', 'way', 'was', 'following', 'bye', 'make', 'partner', 'offended', 'soccer', 'boogers', 'very', 'robot', 'thank', 'quiet', 'hannukah', 'wrong', 'must', 'color', 'brothers', 'count', 'tired', 'homophobic', 'when', 'girl', 'a', 'of', 'hungry', 'did', 'lesbian', 'ask', 'sister', 'kinds', 'located', 'kidding', 'valentines', 'activity', 'ridiculous', 'from', 'her', 'face', 'ha', 'old', 'annoyed', 'boyfriend', 'siri', 'yesterday', 'ever', 'saying', 'run', 'sing', 'out', 'high', 'sleep', 'life', 'starving', 'and', 'hi', 'who', 'away', 'got', 'bad', 'omg', 'tell', 'country', 'why', 'google', 'purpose', 'good-looking', 'moi', 'straight', 'day', 'happy', 'chat', 'take', 'dad', 'things', 'shush', 'soon', 'thing', 'cares', 'different', 'republican', 'sleepy', 'today', 'sucks', 'siblings', 'yup', 'say', 'nope', 'about', 'this', 'gon', 'else', 'cracking', 'unemployed', 'genius', 'nothing', 'live', 'technology', 'sry', 'tuckered', 'mood', 'available', 'you', 'the', 'like', 'off', 'smart', '7', 'skynet', 'answering', 'play', 'terrible', 'accurate', 'busy', 'state', 'slip', 'man', 'where', 'giving', 'another', 'just', 'met', 'angry', 'hal', 'tomorrow', 'really', 'honestly', 'such', 'any', 'sad', 'up', 'age', 'singularity', 'him', 'hiya', 'stupid', 'let', 'lame', 'responses', 'ticked', 'keep', 'no', 'time', 'want', 'drive', 'know', 'uninteresting', 'beg', 'games', 'job', 'around', 'come', 'i', 'alligator', 'goodbye', 'bed', 'works', 'cook', 'jokes', 'guy', 'wonderful', 'should', 'excuse', 'at', 'will', 'pissed', 'likes', 'yes', 'think', 'fired', 'hum', 'into', 'beautiful', 'answers', 'asexual', 'could', 'boy', 'sadness', 'furious', \"'s\", 'family', 'your', 'believe', 'christmas', 'chipper', 'fun', 'lie', 'with', 'apples', 'racist', 'million', 'tunes', 'shopping', 'boring', 'be', 'get', 'is', 'york', 'later', 'does', 'discrimination', 'worst', 'chewing', 'correct', 'gum', 'married', 'awful', 'bore', 'okay', 'candy', 'joke', '2', 'hat', 'getting', 'something', 'hate', 'sandwich', 'even', 'not', 'friend', 'girlfriend', 'cortana', 'lay', 'down', 'work', 'biggest', 'how', 'smell', 'dirty', 'imaginary', 'rofl', 'do', 'engineer', 'best', \"'d\", 'feel', 'car', 'greetings', 'female', 'look', 'cheerful', 'were', 'alone', 'nice', 'democrat', 'ugly', 'husband', 'baseball', 'attempting', 'help', 'despondent', 'sexist', 'created', 'sweetheart', 'gender', 'animal', 'fan', 'queer', 'morning', 'can', 'true', 'fly', 'pirate', 'all', 'annoying', 'much', 'chatbots', 'on', 'food', 'halloween', 'basic', 'an', 'trans', 'ago', 'swell', 'making', 'going', 'music', 'lonely', 'jump', 'silly', 'dream', 'false', 'mind', 'would', 'love', 'season', 'real', 'adore', 'hang', 'till', 'friends', 'na', 'answer', 'understand', 'made', 'heya', 'now', 'human', 'rule', 'read', 'song', 'interest', 'tall', 'sounds', 'pardon', 'world', 'or', 'domination', 'gay', 'have', 'told', 'garden', 'kind', 'singer', 'person', 'funny', 'me', 'hilarious', 'male', 'sense', 'free', 'mother', 'anymore', 'people', 'unfunny', 'tune', 'woman', 'offensive', 'science', 'makes', 'merry', 'bingo', 'cats', 'spend', 'af', 'joyous', 'teams', 'brother', 'sung', 'master', 'favorite', 'alexa', 'young', 'bisexual', 'to', 'by', 'night', 'playing', 'creator', 'awesome', 'same', 'in', 'longer', 'hello', 'change', 'computers', 'seem', 'go', 'talking', 'my', 'house', 'birthday', 'see', 'famished', 'oops', 'mad', 'happening', 'right', 'dating', 'afraid', 'daddy', 'relationship', 'sweat', 'intelligent', 'cool', 'ai', 'am', 'forever', 'rest', 'team', 'hear', 'movie', 'again', 'talk', 'wife', 'give', 'sneeze', 'question', 'dumb', 'inaccurate', 'vacation', 'some', 'employed', 'shut', 'sincere', 'haha', 'hahaha', 'thanks', 'try', 'it', 'great', 'doing', 'pretty', 'bots', 'boss', 'so', 'everything', 'blue', 'tech', '3', 'engaged', 'good', 'wish', 'are']\n"
     ]
    }
   ],
   "source": [
    "#list of vocab in a columns dataframe\n",
    "\n",
    "def listword(df):\n",
    "    list_word = [i for j in df for i in j]\n",
    "    return list_word\n",
    "list_word = listword(question_transform)\n",
    "\n",
    "#list vocab from sample question\n",
    "def vocab(df):\n",
    "    list_word_set = list(set(df))\n",
    "    return list_word_set\n",
    "\n",
    "list_word_set = vocab(list_word)\n",
    "print(list_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "list vocab in sample question: ['report', 'full', 'pink', 'lol', 'anything', 'zip', 'haircut', 'other', 'that', 'stop', 'nobody', 'mom', 'marry', '1', 'name', 'born', 'agents', 'sisters', 'call', 'appreciate', 'long', 'songs', 'ready', 'sports', 'new', 'here', 'fake', 'owns', 'dreamy', 'anyone', 'we', 'more', 'for', 'which', 'what', 'pansexual', 'sorry', 'mean', 'digital', 'bored', 'testing', 'useless', 'meet', 'rad', 'father', 'eat', 'date', 'feeling', 'there', 'way', 'was', 'following', 'bye', 'make', 'partner', 'offended', 'soccer', 'boogers', 'very', 'robot', 'thank', 'quiet', 'hannukah', 'wrong', 'must', 'color', 'brothers', 'count', 'tired', 'homophobic', 'when', 'girl', 'a', 'of', 'hungry', 'did', 'lesbian', 'ask', 'sister', 'kinds', 'located', 'kidding', 'valentines', 'activity', 'ridiculous', 'from', 'her', 'face', 'ha', 'old', 'annoyed', 'boyfriend', 'siri', 'yesterday', 'ever', 'saying', 'run', 'sing', 'out', 'high', 'sleep', 'life', 'starving', 'and', 'hi', 'who', 'away', 'got', 'bad', 'omg', 'tell', 'country', 'why', 'google', 'purpose', 'good-looking', 'moi', 'straight', 'day', 'happy', 'chat', 'take', 'dad', 'things', 'shush', 'soon', 'thing', 'cares', 'different', 'republican', 'sleepy', 'today', 'sucks', 'siblings', 'yup', 'say', 'nope', 'about', 'this', 'gon', 'else', 'cracking', 'unemployed', 'genius', 'nothing', 'live', 'technology', 'sry', 'tuckered', 'mood', 'available', 'you', 'the', 'like', 'off', 'smart', '7', 'skynet', 'answering', 'play', 'terrible', 'accurate', 'busy', 'state', 'slip', 'man', 'where', 'giving', 'another', 'just', 'met', 'angry', 'hal', 'tomorrow', 'really', 'honestly', 'such', 'any', 'sad', 'up', 'age', 'singularity', 'him', 'hiya', 'stupid', 'let', 'lame', 'responses', 'ticked', 'keep', 'no', 'time', 'want', 'drive', 'know', 'uninteresting', 'beg', 'games', 'job', 'around', 'come', 'i', 'alligator', 'goodbye', 'bed', 'works', 'cook', 'jokes', 'guy', 'wonderful', 'should', 'excuse', 'at', 'will', 'pissed', 'likes', 'yes', 'think', 'fired', 'hum', 'into', 'beautiful', 'answers', 'asexual', 'could', 'boy', 'sadness', 'furious', \"'s\", 'family', 'your', 'believe', 'christmas', 'chipper', 'fun', 'lie', 'with', 'apples', 'racist', 'million', 'tunes', 'shopping', 'boring', 'be', 'get', 'is', 'york', 'later', 'does', 'discrimination', 'worst', 'chewing', 'correct', 'gum', 'married', 'awful', 'bore', 'okay', 'candy', 'joke', '2', 'hat', 'getting', 'something', 'hate', 'sandwich', 'even', 'not', 'friend', 'girlfriend', 'cortana', 'lay', 'down', 'work', 'biggest', 'how', 'smell', 'dirty', 'imaginary', 'rofl', 'do', 'engineer', 'best', \"'d\", 'feel', 'car', 'greetings', 'female', 'look', 'cheerful', 'were', 'alone', 'nice', 'democrat', 'ugly', 'husband', 'baseball', 'attempting', 'help', 'despondent', 'sexist', 'created', 'sweetheart', 'gender', 'animal', 'fan', 'queer', 'morning', 'can', 'true', 'fly', 'pirate', 'all', 'annoying', 'much', 'chatbots', 'on', 'food', 'halloween', 'basic', 'an', 'trans', 'ago', 'swell', 'making', 'going', 'music', 'lonely', 'jump', 'silly', 'dream', 'false', 'mind', 'would', 'love', 'season', 'real', 'adore', 'hang', 'till', 'friends', 'na', 'answer', 'understand', 'made', 'heya', 'now', 'human', 'rule', 'read', 'song', 'interest', 'tall', 'sounds', 'pardon', 'world', 'or', 'domination', 'gay', 'have', 'told', 'garden', 'kind', 'singer', 'person', 'funny', 'me', 'hilarious', 'male', 'sense', 'free', 'mother', 'anymore', 'people', 'unfunny', 'tune', 'woman', 'offensive', 'science', 'makes', 'merry', 'bingo', 'cats', 'spend', 'af', 'joyous', 'teams', 'brother', 'sung', 'master', 'favorite', 'alexa', 'young', 'bisexual', 'to', 'by', 'night', 'playing', 'creator', 'awesome', 'same', 'in', 'longer', 'hello', 'change', 'computers', 'seem', 'go', 'talking', 'my', 'house', 'birthday', 'see', 'famished', 'oops', 'mad', 'happening', 'right', 'dating', 'afraid', 'daddy', 'relationship', 'sweat', 'intelligent', 'cool', 'ai', 'am', 'forever', 'rest', 'team', 'hear', 'movie', 'again', 'talk', 'wife', 'give', 'sneeze', 'question', 'dumb', 'inaccurate', 'vacation', 'some', 'employed', 'shut', 'sincere', 'haha', 'hahaha', 'thanks', 'try', 'it', 'great', 'doing', 'pretty', 'bots', 'boss', 'so', 'everything', 'blue', 'tech', '3', 'engaged', 'good', 'wish', 'are']\n",
      "--------------------------------------------------\n",
      "The word is miss: ['hannukah', 'skynet', 'cortana']\n"
     ]
    }
   ],
   "source": [
    "vocab_ = list(fasttext.vocab) #list vocab in gensim --> not enough word from sample question list\n",
    "print(len(vocab_))\n",
    "not_enough = [i for i in list_word_set if i not in vocab_]\n",
    "\n",
    "print('list vocab in sample question:', list_word_set)\n",
    "print('-'*50)\n",
    "print('The word is miss:', not_enough)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508, 76)\n",
      "(76, 76)\n",
      "(584, 76)\n"
     ]
    }
   ],
   "source": [
    "#Transfer label from column intent into one hot encoding\n",
    "def one_hot_encodeing(feature):\n",
    "\n",
    "    onehot = np.zeros((len(feature), feature.nunique()))\n",
    "    feature_list = list(feature.unique())\n",
    "    for intent in range(len(feature)):\n",
    "        index = feature_list.index(feature[intent])\n",
    "        onehot[intent, index] = 1\n",
    "    return onehot, feature_list\n",
    "\n",
    "train_onehot, train_feature = one_hot_encodeing(data_train['Answer'])\n",
    "test_onehot, test_feature = one_hot_encodeing(data_test['Answer'])\n",
    "onehot_, feature_ = one_hot_encodeing(data0['Answer'])\n",
    "print(train_onehot.shape)\n",
    "print(test_onehot.shape)\n",
    "print(onehot_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508, 10, 300)\n",
      "(76, 10, 300)\n"
     ]
    }
   ],
   "source": [
    "#Creat a matrix from sample question with the dimention is row x max_lenght x 100\n",
    "def word_embed(df, model, max_length):\n",
    "    embed_all = []\n",
    "    for word_split in df:\n",
    "\n",
    "        if len(word_split) > 0:\n",
    "            embed_token = []\n",
    "            for word in word_split:\n",
    "                if word in vocab_:\n",
    " \n",
    "                    vec = model[word]\n",
    "                    embed_token.append(vec)\n",
    "\n",
    "            if len(embed_token) != 0:\n",
    "                if len(embed_token) >= max_length: #if len(embed_token) > max_length then remove in larger\n",
    "                    embed_token = embed_token[:max_length]\n",
    "                else: #if len(embed_token) < max_length then add 0 for enough\n",
    "                    add_vect = list(np.zeros((max_length - len(embed_token), 300)))\n",
    "                    embed_token = np.concatenate((embed_token, add_vect))\n",
    "\n",
    "            else:\n",
    "                print(False)\n",
    "\n",
    "        else:\n",
    "            print(False)\n",
    "        embed_all.append(embed_token)\n",
    "    return np.asarray(embed_all)\n",
    "\n",
    "#Train, test data to vector\n",
    "all_ = word_embed(question_transform, fasttext, 10)\n",
    "train = word_embed(question_transform_train, fasttext, 10)\n",
    "test = word_embed(question_transform_test, fasttext, 10)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creat LSTM model with input_shape = max_lengh x 100\n",
    "def LSTM_(X, y, input_dim, epoch, batch_size, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, return_sequences=True, input_shape=(input_dim)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=output_dim, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='Adam', \n",
    "                 metrics=['accuracy'])\n",
    "    if not os.path.exists('keras_model'):\n",
    "        os.makedirs('keras_model')\n",
    "    save_weight = os.path.join('keras_model', 'LSTM_weight.{loss:.4f}.hdf5')\n",
    "    save_best = ModelCheckpoint(save_weight, monitor='loss', save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X, y, epochs=epoch, batch_size=batch_size, callbacks=[save_best])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat Model check points for model save best loss in each epoch, if loss new smaller than all file saved, it will save a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 64)            37056     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 76)                2508      \n",
      "=================================================================\n",
      "Total params: 271,628\n",
      "Trainable params: 271,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "508/508 [==============================] - 3s 6ms/step - loss: 4.3270 - acc: 0.0295\n",
      "Epoch 2/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 4.2622 - acc: 0.0531\n",
      "Epoch 3/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 4.1458 - acc: 0.0276\n",
      "Epoch 4/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 4.0701 - acc: 0.0472\n",
      "Epoch 5/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.9537 - acc: 0.0689\n",
      "Epoch 6/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 3.8656 - acc: 0.0787\n",
      "Epoch 7/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.7778 - acc: 0.0965\n",
      "Epoch 8/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.7027 - acc: 0.0846\n",
      "Epoch 9/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.6447 - acc: 0.0945\n",
      "Epoch 10/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.5718 - acc: 0.1142\n",
      "Epoch 11/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.4705 - acc: 0.1496\n",
      "Epoch 12/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.4337 - acc: 0.1496\n",
      "Epoch 13/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.3576 - acc: 0.1713\n",
      "Epoch 14/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.2458 - acc: 0.1988\n",
      "Epoch 15/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.1793 - acc: 0.2008\n",
      "Epoch 16/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 3.1241 - acc: 0.2067\n",
      "Epoch 17/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.0082 - acc: 0.2224\n",
      "Epoch 18/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 3.0050 - acc: 0.2224\n",
      "Epoch 19/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.8853 - acc: 0.2461\n",
      "Epoch 20/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.8353 - acc: 0.2638\n",
      "Epoch 21/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.7582 - acc: 0.2677\n",
      "Epoch 22/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.6918 - acc: 0.3091\n",
      "Epoch 23/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.6752 - acc: 0.3169\n",
      "Epoch 24/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.6393 - acc: 0.3110\n",
      "Epoch 25/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.5643 - acc: 0.3524\n",
      "Epoch 26/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.5527 - acc: 0.3386\n",
      "Epoch 27/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.5389 - acc: 0.3209\n",
      "Epoch 28/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.4034 - acc: 0.3858\n",
      "Epoch 29/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.3453 - acc: 0.4035\n",
      "Epoch 30/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.3028 - acc: 0.4213\n",
      "Epoch 31/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.2774 - acc: 0.4094\n",
      "Epoch 32/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.2722 - acc: 0.4173\n",
      "Epoch 33/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.2417 - acc: 0.4272\n",
      "Epoch 34/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.1676 - acc: 0.4213\n",
      "Epoch 35/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.1499 - acc: 0.4291\n",
      "Epoch 36/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 2.1050 - acc: 0.4587\n",
      "Epoch 37/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.0790 - acc: 0.4449\n",
      "Epoch 38/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 2.0327 - acc: 0.4980\n",
      "Epoch 39/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.9721 - acc: 0.4980\n",
      "Epoch 40/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.9429 - acc: 0.5374\n",
      "Epoch 41/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.9444 - acc: 0.5020\n",
      "Epoch 42/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.8639 - acc: 0.5531\n",
      "Epoch 43/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.8853 - acc: 0.5039\n",
      "Epoch 44/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.8429 - acc: 0.5492\n",
      "Epoch 45/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.7749 - acc: 0.5413\n",
      "Epoch 46/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.7908 - acc: 0.5531\n",
      "Epoch 47/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.7252 - acc: 0.5551\n",
      "Epoch 48/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.6651 - acc: 0.6122\n",
      "Epoch 49/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.7140 - acc: 0.5748\n",
      "Epoch 50/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.6226 - acc: 0.6240\n",
      "Epoch 51/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.5949 - acc: 0.6260\n",
      "Epoch 52/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.5340 - acc: 0.6063\n",
      "Epoch 53/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.5278 - acc: 0.6220\n",
      "Epoch 54/1000\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 1.4645 - acc: 0.6457\n",
      "Epoch 55/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.4554 - acc: 0.6516\n",
      "Epoch 56/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.4398 - acc: 0.6319\n",
      "Epoch 57/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.4035 - acc: 0.6673\n",
      "Epoch 58/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.3925 - acc: 0.6732\n",
      "Epoch 59/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.3356 - acc: 0.6811\n",
      "Epoch 60/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.3339 - acc: 0.6850\n",
      "Epoch 61/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.3012 - acc: 0.7008\n",
      "Epoch 62/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.3042 - acc: 0.6831\n",
      "Epoch 63/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.2634 - acc: 0.7165\n",
      "Epoch 64/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.2151 - acc: 0.7283\n",
      "Epoch 65/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.1869 - acc: 0.7067\n",
      "Epoch 66/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.2143 - acc: 0.7165\n",
      "Epoch 67/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.2216 - acc: 0.7047\n",
      "Epoch 68/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.1665 - acc: 0.7224\n",
      "Epoch 69/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.1182 - acc: 0.7441\n",
      "Epoch 70/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.0789 - acc: 0.7480\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 1.0822 - acc: 0.7441\n",
      "Epoch 72/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.0236 - acc: 0.7638\n",
      "Epoch 73/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.9895 - acc: 0.7815\n",
      "Epoch 74/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.9697 - acc: 0.8071\n",
      "Epoch 75/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.0057 - acc: 0.7894\n",
      "Epoch 76/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 1.0726 - acc: 0.7520\n",
      "Epoch 77/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 1.0330 - acc: 0.7677\n",
      "Epoch 78/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.9247 - acc: 0.8051\n",
      "Epoch 79/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.9331 - acc: 0.8169\n",
      "Epoch 80/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.9224 - acc: 0.8071\n",
      "Epoch 81/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.8911 - acc: 0.8110\n",
      "Epoch 82/1000\n",
      "508/508 [==============================] - 1s 989us/step - loss: 0.8505 - acc: 0.8445\n",
      "Epoch 83/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.8125 - acc: 0.8484\n",
      "Epoch 84/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.8172 - acc: 0.8307\n",
      "Epoch 85/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7981 - acc: 0.8484\n",
      "Epoch 86/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7957 - acc: 0.8484\n",
      "Epoch 87/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7784 - acc: 0.8504\n",
      "Epoch 88/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.7503 - acc: 0.8583\n",
      "Epoch 89/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7544 - acc: 0.8563\n",
      "Epoch 90/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.7644 - acc: 0.8307\n",
      "Epoch 91/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7585 - acc: 0.8445\n",
      "Epoch 92/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7312 - acc: 0.8563\n",
      "Epoch 93/1000\n",
      "508/508 [==============================] - 1s 990us/step - loss: 0.6957 - acc: 0.8701\n",
      "Epoch 94/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.7631 - acc: 0.8386\n",
      "Epoch 95/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.6748 - acc: 0.8898\n",
      "Epoch 96/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.6393 - acc: 0.9035\n",
      "Epoch 97/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5993 - acc: 0.9094\n",
      "Epoch 98/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.6355 - acc: 0.8937\n",
      "Epoch 99/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.6258 - acc: 0.8760\n",
      "Epoch 100/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5995 - acc: 0.8898\n",
      "Epoch 101/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5587 - acc: 0.8996\n",
      "Epoch 102/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5437 - acc: 0.9075\n",
      "Epoch 103/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4871 - acc: 0.9291\n",
      "Epoch 104/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5241 - acc: 0.9232\n",
      "Epoch 105/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4993 - acc: 0.9232\n",
      "Epoch 106/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5312 - acc: 0.9213\n",
      "Epoch 107/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4927 - acc: 0.9055\n",
      "Epoch 108/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4872 - acc: 0.9094\n",
      "Epoch 109/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4716 - acc: 0.8996\n",
      "Epoch 110/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4556 - acc: 0.9370\n",
      "Epoch 111/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4595 - acc: 0.9331\n",
      "Epoch 112/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4247 - acc: 0.9547\n",
      "Epoch 113/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4483 - acc: 0.9193\n",
      "Epoch 114/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4282 - acc: 0.9488\n",
      "Epoch 115/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4590 - acc: 0.9252\n",
      "Epoch 116/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4444 - acc: 0.9311\n",
      "Epoch 117/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4297 - acc: 0.9449\n",
      "Epoch 118/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3949 - acc: 0.9508\n",
      "Epoch 119/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3991 - acc: 0.9547\n",
      "Epoch 120/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3612 - acc: 0.9488\n",
      "Epoch 121/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3502 - acc: 0.9528\n",
      "Epoch 122/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3681 - acc: 0.9469\n",
      "Epoch 123/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3876 - acc: 0.9390\n",
      "Epoch 124/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3710 - acc: 0.9469\n",
      "Epoch 125/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3261 - acc: 0.9606\n",
      "Epoch 126/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3631 - acc: 0.9409\n",
      "Epoch 127/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3563 - acc: 0.9370\n",
      "Epoch 128/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3558 - acc: 0.9488\n",
      "Epoch 129/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3854 - acc: 0.9311\n",
      "Epoch 130/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3601 - acc: 0.9350\n",
      "Epoch 131/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3469 - acc: 0.9331\n",
      "Epoch 132/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3196 - acc: 0.9547\n",
      "Epoch 133/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3114 - acc: 0.9646\n",
      "Epoch 134/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2742 - acc: 0.9626\n",
      "Epoch 135/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2774 - acc: 0.9606\n",
      "Epoch 136/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2751 - acc: 0.9705\n",
      "Epoch 137/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2866 - acc: 0.9665\n",
      "Epoch 138/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2713 - acc: 0.9724\n",
      "Epoch 139/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2777 - acc: 0.9587\n",
      "Epoch 140/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2553 - acc: 0.9685\n",
      "Epoch 141/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2732 - acc: 0.9606\n",
      "Epoch 142/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2485 - acc: 0.9685\n",
      "Epoch 143/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2514 - acc: 0.9646\n",
      "Epoch 144/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2379 - acc: 0.9685\n",
      "Epoch 145/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2328 - acc: 0.9724\n",
      "Epoch 146/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2228 - acc: 0.9744\n",
      "Epoch 147/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2727 - acc: 0.9567\n",
      "Epoch 148/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2828 - acc: 0.9567\n",
      "Epoch 149/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2573 - acc: 0.9567\n",
      "Epoch 150/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2450 - acc: 0.9744\n",
      "Epoch 151/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2193 - acc: 0.9764\n",
      "Epoch 152/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2328 - acc: 0.9665\n",
      "Epoch 153/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2632 - acc: 0.9587\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2059 - acc: 0.9685\n",
      "Epoch 155/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2068 - acc: 0.9862\n",
      "Epoch 156/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1859 - acc: 0.9803\n",
      "Epoch 157/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2026 - acc: 0.9705\n",
      "Epoch 158/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2267 - acc: 0.9744\n",
      "Epoch 159/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2357 - acc: 0.9646\n",
      "Epoch 160/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2570 - acc: 0.9606\n",
      "Epoch 161/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2308 - acc: 0.9724\n",
      "Epoch 162/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2014 - acc: 0.9744\n",
      "Epoch 163/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2798 - acc: 0.9409\n",
      "Epoch 164/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2380 - acc: 0.9587\n",
      "Epoch 165/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2175 - acc: 0.9626\n",
      "Epoch 166/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2402 - acc: 0.9567\n",
      "Epoch 167/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2273 - acc: 0.9665\n",
      "Epoch 168/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2087 - acc: 0.9724\n",
      "Epoch 169/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1984 - acc: 0.9685\n",
      "Epoch 170/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1920 - acc: 0.9764\n",
      "Epoch 171/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1670 - acc: 0.9823\n",
      "Epoch 172/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.1702 - acc: 0.9843\n",
      "Epoch 173/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.1563 - acc: 0.9902\n",
      "Epoch 174/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1404 - acc: 0.9921\n",
      "Epoch 175/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.1457 - acc: 0.9862\n",
      "Epoch 176/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.1513 - acc: 0.9823\n",
      "Epoch 177/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1501 - acc: 0.9803A: 0s - loss: 0.1474 - acc: \n",
      "Epoch 178/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1541 - acc: 0.9783\n",
      "Epoch 179/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1415 - acc: 0.9902\n",
      "Epoch 180/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1285 - acc: 0.9843\n",
      "Epoch 181/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1376 - acc: 0.9783\n",
      "Epoch 182/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1425 - acc: 0.9921\n",
      "Epoch 183/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1243 - acc: 0.9941\n",
      "Epoch 184/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1241 - acc: 0.9902\n",
      "Epoch 185/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1253 - acc: 0.9941\n",
      "Epoch 186/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1323 - acc: 0.9803\n",
      "Epoch 187/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1535 - acc: 0.9764\n",
      "Epoch 188/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.1681 - acc: 0.9744\n",
      "Epoch 189/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1555 - acc: 0.9803\n",
      "Epoch 190/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1518 - acc: 0.9744\n",
      "Epoch 191/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1287 - acc: 0.9843\n",
      "Epoch 192/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1465 - acc: 0.9724\n",
      "Epoch 193/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1723 - acc: 0.9744\n",
      "Epoch 194/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1746 - acc: 0.9724\n",
      "Epoch 195/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1416 - acc: 0.9823\n",
      "Epoch 196/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1502 - acc: 0.9764\n",
      "Epoch 197/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1327 - acc: 0.9882\n",
      "Epoch 198/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1176 - acc: 0.9902\n",
      "Epoch 199/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1055 - acc: 0.9882\n",
      "Epoch 200/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1080 - acc: 0.9862\n",
      "Epoch 201/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1198 - acc: 0.9882\n",
      "Epoch 202/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0994 - acc: 0.9921\n",
      "Epoch 203/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1056 - acc: 0.9882\n",
      "Epoch 204/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0918 - acc: 0.9941\n",
      "Epoch 205/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0937 - acc: 0.9902\n",
      "Epoch 206/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0891 - acc: 0.9941\n",
      "Epoch 207/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0923 - acc: 0.9882\n",
      "Epoch 208/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1008 - acc: 0.9902A: 0s - loss: 0.1001 - acc: 0.991\n",
      "Epoch 209/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1013 - acc: 0.9862\n",
      "Epoch 210/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0863 - acc: 0.9921\n",
      "Epoch 211/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0847 - acc: 0.9921\n",
      "Epoch 212/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0965 - acc: 0.9921\n",
      "Epoch 213/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0866 - acc: 0.9882\n",
      "Epoch 214/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 215/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0774 - acc: 0.9941\n",
      "Epoch 216/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0867 - acc: 0.9921\n",
      "Epoch 217/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0772 - acc: 0.9941\n",
      "Epoch 218/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0809 - acc: 0.9902\n",
      "Epoch 219/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0750 - acc: 0.9941\n",
      "Epoch 220/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0750 - acc: 0.9941\n",
      "Epoch 221/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0751 - acc: 0.9921\n",
      "Epoch 222/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0786 - acc: 0.9961\n",
      "Epoch 223/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0785 - acc: 0.9941\n",
      "Epoch 224/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0811 - acc: 0.9921\n",
      "Epoch 225/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0766 - acc: 0.9902\n",
      "Epoch 226/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0873 - acc: 0.9882\n",
      "Epoch 227/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0736 - acc: 0.9941\n",
      "Epoch 228/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0727 - acc: 0.9902\n",
      "Epoch 229/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0848 - acc: 0.9941\n",
      "Epoch 230/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0663 - acc: 0.9961\n",
      "Epoch 231/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0819 - acc: 0.9902\n",
      "Epoch 232/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0992 - acc: 0.9921\n",
      "Epoch 233/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0775 - acc: 0.9902\n",
      "Epoch 234/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0818 - acc: 0.9941\n",
      "Epoch 235/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1042 - acc: 0.9843\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1247 - acc: 0.9803\n",
      "Epoch 237/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1344 - acc: 0.9705\n",
      "Epoch 238/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1109 - acc: 0.9862\n",
      "Epoch 239/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1622 - acc: 0.9665\n",
      "Epoch 240/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1617 - acc: 0.9705\n",
      "Epoch 241/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1559 - acc: 0.9685\n",
      "Epoch 242/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1247 - acc: 0.9823\n",
      "Epoch 243/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1186 - acc: 0.9803\n",
      "Epoch 244/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0976 - acc: 0.9823\n",
      "Epoch 245/1000\n",
      "508/508 [==============================] - 0s 980us/step - loss: 0.1020 - acc: 0.9783\n",
      "Epoch 246/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0789 - acc: 0.9921\n",
      "Epoch 247/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0994 - acc: 0.9783\n",
      "Epoch 248/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0704 - acc: 0.9980\n",
      "Epoch 249/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0703 - acc: 0.9961\n",
      "Epoch 250/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0606 - acc: 0.9961\n",
      "Epoch 251/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0594 - acc: 0.9961\n",
      "Epoch 252/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0616 - acc: 0.9902\n",
      "Epoch 253/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0548 - acc: 0.9941\n",
      "Epoch 254/1000\n",
      "508/508 [==============================] - 0s 967us/step - loss: 0.0624 - acc: 0.9902\n",
      "Epoch 255/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0549 - acc: 0.9961\n",
      "Epoch 256/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0589 - acc: 0.9941\n",
      "Epoch 257/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0899 - acc: 0.9862\n",
      "Epoch 258/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1067 - acc: 0.9783\n",
      "Epoch 259/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0675 - acc: 0.9902A: 0s - loss: 0.0678 - acc: \n",
      "Epoch 260/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0915 - acc: 0.9823\n",
      "Epoch 261/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0865 - acc: 0.9882\n",
      "Epoch 262/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0808 - acc: 0.9823\n",
      "Epoch 263/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0859 - acc: 0.9862\n",
      "Epoch 264/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1170 - acc: 0.9764\n",
      "Epoch 265/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0976 - acc: 0.9823\n",
      "Epoch 266/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1067 - acc: 0.9764\n",
      "Epoch 267/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1027 - acc: 0.9823\n",
      "Epoch 268/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0777 - acc: 0.9902\n",
      "Epoch 269/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0696 - acc: 0.9941\n",
      "Epoch 270/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0564 - acc: 0.9921\n",
      "Epoch 271/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0620 - acc: 0.9921\n",
      "Epoch 272/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0599 - acc: 0.9921\n",
      "Epoch 273/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0551 - acc: 0.9941\n",
      "Epoch 274/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0581 - acc: 0.9921\n",
      "Epoch 275/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0534 - acc: 0.9902\n",
      "Epoch 276/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0498 - acc: 0.9921\n",
      "Epoch 277/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0483 - acc: 0.9961\n",
      "Epoch 278/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0620 - acc: 0.9902\n",
      "Epoch 279/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0542 - acc: 0.9921\n",
      "Epoch 280/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0486 - acc: 0.9941\n",
      "Epoch 281/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0418 - acc: 0.9980\n",
      "Epoch 282/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0580 - acc: 0.9961\n",
      "Epoch 283/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0662 - acc: 0.9882\n",
      "Epoch 284/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0669 - acc: 0.9843\n",
      "Epoch 285/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0807 - acc: 0.9862\n",
      "Epoch 286/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0688 - acc: 0.9783\n",
      "Epoch 287/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0921 - acc: 0.9843\n",
      "Epoch 288/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0657 - acc: 0.9921\n",
      "Epoch 289/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0507 - acc: 0.9961\n",
      "Epoch 290/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0502 - acc: 0.9921\n",
      "Epoch 291/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0481 - acc: 0.9902\n",
      "Epoch 292/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0376 - acc: 0.9961\n",
      "Epoch 293/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0396 - acc: 0.9980\n",
      "Epoch 294/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0419 - acc: 0.9961\n",
      "Epoch 295/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0457 - acc: 0.9961\n",
      "Epoch 296/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0435 - acc: 0.9921\n",
      "Epoch 297/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0373 - acc: 0.9961\n",
      "Epoch 298/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0478 - acc: 0.9980\n",
      "Epoch 299/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0388 - acc: 0.9980\n",
      "Epoch 300/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0367 - acc: 0.9980\n",
      "Epoch 301/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0357 - acc: 0.9980\n",
      "Epoch 302/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0390 - acc: 0.9961\n",
      "Epoch 303/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0377 - acc: 0.9941\n",
      "Epoch 304/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0366 - acc: 0.9961\n",
      "Epoch 305/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0417 - acc: 0.9961\n",
      "Epoch 306/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0372 - acc: 0.9941\n",
      "Epoch 307/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0389 - acc: 0.9961\n",
      "Epoch 308/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0410 - acc: 0.9941\n",
      "Epoch 309/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9961\n",
      "Epoch 310/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0390 - acc: 0.9941\n",
      "Epoch 311/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0381 - acc: 0.9921\n",
      "Epoch 312/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0373 - acc: 0.9941\n",
      "Epoch 313/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0378 - acc: 0.9961\n",
      "Epoch 314/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0367 - acc: 0.9921\n",
      "Epoch 315/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0305 - acc: 0.9961\n",
      "Epoch 316/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0283 - acc: 0.9961\n",
      "Epoch 317/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0337 - acc: 0.9961\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0305 - acc: 0.9980\n",
      "Epoch 319/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0377 - acc: 0.9941\n",
      "Epoch 320/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0365 - acc: 0.9961\n",
      "Epoch 321/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0315 - acc: 0.9980\n",
      "Epoch 322/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0450 - acc: 0.9882\n",
      "Epoch 323/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0527 - acc: 0.9941\n",
      "Epoch 324/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0584 - acc: 0.9921\n",
      "Epoch 325/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0696 - acc: 0.9823\n",
      "Epoch 326/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3990 - acc: 0.8996\n",
      "Epoch 327/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3831 - acc: 0.8917\n",
      "Epoch 328/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4917 - acc: 0.8720\n",
      "Epoch 329/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4024 - acc: 0.8858\n",
      "Epoch 330/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2625 - acc: 0.9291\n",
      "Epoch 331/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1544 - acc: 0.9705\n",
      "Epoch 332/1000\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.1106 - acc: 0.977 - 1s 1ms/step - loss: 0.1094 - acc: 0.9783\n",
      "Epoch 333/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0884 - acc: 0.9744\n",
      "Epoch 334/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0569 - acc: 0.9961\n",
      "Epoch 335/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0495 - acc: 0.9961\n",
      "Epoch 336/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0470 - acc: 0.9961\n",
      "Epoch 337/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0569 - acc: 0.9941\n",
      "Epoch 338/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0560 - acc: 0.9941\n",
      "Epoch 339/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0434 - acc: 0.9921\n",
      "Epoch 340/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0472 - acc: 0.9941\n",
      "Epoch 341/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0459 - acc: 0.9921\n",
      "Epoch 342/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0422 - acc: 0.9921\n",
      "Epoch 343/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0507 - acc: 0.9902\n",
      "Epoch 344/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0384 - acc: 0.9941\n",
      "Epoch 345/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0366 - acc: 0.9941\n",
      "Epoch 346/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0386 - acc: 0.9941\n",
      "Epoch 347/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0350 - acc: 0.9941\n",
      "Epoch 348/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0340 - acc: 0.9941\n",
      "Epoch 349/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0365 - acc: 0.9921\n",
      "Epoch 350/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0333 - acc: 0.9980\n",
      "Epoch 351/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9961\n",
      "Epoch 352/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 353/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0345 - acc: 0.9980\n",
      "Epoch 354/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0337 - acc: 0.9921\n",
      "Epoch 355/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0297 - acc: 0.9961\n",
      "Epoch 356/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0264 - acc: 0.9961\n",
      "Epoch 357/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0327 - acc: 0.9941\n",
      "Epoch 358/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0313 - acc: 0.9941\n",
      "Epoch 359/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0286 - acc: 0.9941\n",
      "Epoch 360/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0298 - acc: 0.9961\n",
      "Epoch 361/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0336 - acc: 0.9921\n",
      "Epoch 362/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0273 - acc: 0.9980\n",
      "Epoch 363/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0318 - acc: 0.9961\n",
      "Epoch 364/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0289 - acc: 0.9961\n",
      "Epoch 365/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0302 - acc: 0.9961\n",
      "Epoch 366/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0312 - acc: 0.9941\n",
      "Epoch 367/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0233 - acc: 0.9980\n",
      "Epoch 368/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0288 - acc: 0.9961\n",
      "Epoch 369/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0281 - acc: 0.9902\n",
      "Epoch 370/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0310 - acc: 0.9961\n",
      "Epoch 371/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0316 - acc: 0.9941\n",
      "Epoch 372/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0284 - acc: 0.9961\n",
      "Epoch 373/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0262 - acc: 0.9941\n",
      "Epoch 374/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0266 - acc: 0.9961\n",
      "Epoch 375/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0284 - acc: 0.9961\n",
      "Epoch 376/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0278 - acc: 0.9921\n",
      "Epoch 377/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0262 - acc: 0.9980\n",
      "Epoch 378/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0290 - acc: 0.9941\n",
      "Epoch 379/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0272 - acc: 0.9961\n",
      "Epoch 380/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0275 - acc: 0.9921\n",
      "Epoch 381/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0274 - acc: 0.9941\n",
      "Epoch 382/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0235 - acc: 0.9961\n",
      "Epoch 383/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0253 - acc: 0.9921\n",
      "Epoch 384/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0267 - acc: 0.9941\n",
      "Epoch 385/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 386/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0250 - acc: 0.9961\n",
      "Epoch 387/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0298 - acc: 0.9921\n",
      "Epoch 388/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0282 - acc: 0.9921\n",
      "Epoch 389/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0253 - acc: 0.9961\n",
      "Epoch 390/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0271 - acc: 0.9941\n",
      "Epoch 391/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0276 - acc: 0.9941\n",
      "Epoch 392/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9980\n",
      "Epoch 393/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0297 - acc: 0.9961\n",
      "Epoch 394/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0307 - acc: 0.9921\n",
      "Epoch 395/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9961\n",
      "Epoch 396/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0237 - acc: 0.9961\n",
      "Epoch 397/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0236 - acc: 0.9961\n",
      "Epoch 398/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0239 - acc: 0.9941\n",
      "Epoch 399/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0267 - acc: 0.9961\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0263 - acc: 0.9921\n",
      "Epoch 401/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 402/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0266 - acc: 0.9961\n",
      "Epoch 403/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0302 - acc: 0.9921\n",
      "Epoch 404/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0284 - acc: 0.9941\n",
      "Epoch 405/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0244 - acc: 0.9961\n",
      "Epoch 406/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0265 - acc: 0.9921\n",
      "Epoch 407/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0257 - acc: 0.9941\n",
      "Epoch 408/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0240 - acc: 0.9941\n",
      "Epoch 409/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0228 - acc: 0.9941\n",
      "Epoch 410/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 411/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0195 - acc: 0.9961\n",
      "Epoch 412/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0225 - acc: 0.9941\n",
      "Epoch 413/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0211 - acc: 0.9941\n",
      "Epoch 414/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0201 - acc: 0.9980\n",
      "Epoch 415/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0192 - acc: 0.9961\n",
      "Epoch 416/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0221 - acc: 0.9941\n",
      "Epoch 417/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0316 - acc: 0.9921\n",
      "Epoch 418/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0404 - acc: 0.9882\n",
      "Epoch 419/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0736 - acc: 0.9803\n",
      "Epoch 420/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0799 - acc: 0.9803\n",
      "Epoch 421/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0632 - acc: 0.9843\n",
      "Epoch 422/1000\n",
      "508/508 [==============================] - 1s 985us/step - loss: 0.0443 - acc: 0.9921\n",
      "Epoch 423/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0304 - acc: 0.9941\n",
      "Epoch 424/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0308 - acc: 0.9961\n",
      "Epoch 425/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0311 - acc: 0.9961\n",
      "Epoch 426/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0276 - acc: 0.9941\n",
      "Epoch 427/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0217 - acc: 0.9980\n",
      "Epoch 428/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9941\n",
      "Epoch 429/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0213 - acc: 0.9961\n",
      "Epoch 430/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 431/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0199 - acc: 0.9961\n",
      "Epoch 432/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0220 - acc: 0.9941\n",
      "Epoch 433/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0202 - acc: 0.9980\n",
      "Epoch 434/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0259 - acc: 0.9921\n",
      "Epoch 435/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0234 - acc: 0.9961\n",
      "Epoch 436/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9941\n",
      "Epoch 437/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0227 - acc: 0.9961\n",
      "Epoch 438/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0193 - acc: 0.9961\n",
      "Epoch 439/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0261 - acc: 0.9961\n",
      "Epoch 440/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0460 - acc: 0.9902\n",
      "Epoch 441/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0718 - acc: 0.9823\n",
      "Epoch 442/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1544 - acc: 0.9528\n",
      "Epoch 443/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4610 - acc: 0.8701\n",
      "Epoch 444/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.5476 - acc: 0.8465\n",
      "Epoch 445/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4943 - acc: 0.8661\n",
      "Epoch 446/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2400 - acc: 0.9350\n",
      "Epoch 447/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0964 - acc: 0.9783\n",
      "Epoch 448/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1173 - acc: 0.9685\n",
      "Epoch 449/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0626 - acc: 0.9843\n",
      "Epoch 450/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0605 - acc: 0.9902\n",
      "Epoch 451/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0619 - acc: 0.9843\n",
      "Epoch 452/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0682 - acc: 0.9882\n",
      "Epoch 453/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0461 - acc: 0.9902\n",
      "Epoch 454/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0434 - acc: 0.9902\n",
      "Epoch 455/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0284 - acc: 0.9921\n",
      "Epoch 456/1000\n",
      "508/508 [==============================] - 0s 935us/step - loss: 0.0353 - acc: 0.9941\n",
      "Epoch 457/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0253 - acc: 0.9961\n",
      "Epoch 458/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0287 - acc: 0.9941\n",
      "Epoch 459/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0242 - acc: 0.9961\n",
      "Epoch 460/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0291 - acc: 0.9921\n",
      "Epoch 461/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0255 - acc: 0.9941\n",
      "Epoch 462/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0298 - acc: 0.9921\n",
      "Epoch 463/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0227 - acc: 0.9980\n",
      "Epoch 464/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0237 - acc: 0.9941\n",
      "Epoch 465/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0245 - acc: 0.9961\n",
      "Epoch 466/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0231 - acc: 0.9961\n",
      "Epoch 467/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.9941\n",
      "Epoch 468/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0201 - acc: 0.9961\n",
      "Epoch 469/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0194 - acc: 0.9961\n",
      "Epoch 470/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0203 - acc: 0.9961\n",
      "Epoch 471/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0240 - acc: 0.9961\n",
      "Epoch 472/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0228 - acc: 0.9941\n",
      "Epoch 473/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0222 - acc: 0.9921\n",
      "Epoch 474/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0186 - acc: 0.9961\n",
      "Epoch 475/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0164 - acc: 0.9961\n",
      "Epoch 476/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0223 - acc: 0.9961\n",
      "Epoch 477/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0222 - acc: 0.9921\n",
      "Epoch 478/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0191 - acc: 0.9980\n",
      "Epoch 479/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0251 - acc: 0.9941\n",
      "Epoch 480/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0214 - acc: 0.9961\n",
      "Epoch 481/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0201 - acc: 0.9961\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0187 - acc: 0.9941\n",
      "Epoch 483/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0202 - acc: 0.9961\n",
      "Epoch 484/1000\n",
      "508/508 [==============================] - 0s 980us/step - loss: 0.0193 - acc: 0.9961\n",
      "Epoch 485/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0204 - acc: 0.9961\n",
      "Epoch 486/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0167 - acc: 0.9980\n",
      "Epoch 487/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 488/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0159 - acc: 0.9980\n",
      "Epoch 489/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 490/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0195 - acc: 0.9980\n",
      "Epoch 491/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0180 - acc: 0.9941\n",
      "Epoch 492/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0160 - acc: 0.9961\n",
      "Epoch 493/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0191 - acc: 0.9961\n",
      "Epoch 494/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0189 - acc: 0.9941\n",
      "Epoch 495/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.9941\n",
      "Epoch 496/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9961\n",
      "Epoch 497/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0166 - acc: 0.9961\n",
      "Epoch 498/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0161 - acc: 0.9961\n",
      "Epoch 499/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0188 - acc: 0.9921\n",
      "Epoch 500/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0152 - acc: 0.9961\n",
      "Epoch 501/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0216 - acc: 0.9961\n",
      "Epoch 502/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0176 - acc: 0.9961\n",
      "Epoch 503/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9961\n",
      "Epoch 504/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 505/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0164 - acc: 0.9961\n",
      "Epoch 506/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0193 - acc: 0.9941\n",
      "Epoch 507/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0181 - acc: 0.9921\n",
      "Epoch 508/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0159 - acc: 0.9980\n",
      "Epoch 509/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 510/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9961\n",
      "Epoch 511/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9980\n",
      "Epoch 512/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9941\n",
      "Epoch 513/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0216 - acc: 0.9941\n",
      "Epoch 514/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0212 - acc: 0.9902\n",
      "Epoch 515/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0186 - acc: 0.9941\n",
      "Epoch 516/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 517/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0167 - acc: 0.9941\n",
      "Epoch 518/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0155 - acc: 0.9961\n",
      "Epoch 519/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9980\n",
      "Epoch 520/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0151 - acc: 0.9980\n",
      "Epoch 521/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0152 - acc: 0.9980\n",
      "Epoch 522/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.9941\n",
      "Epoch 523/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 524/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0131 - acc: 0.9980\n",
      "Epoch 525/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0160 - acc: 0.9961\n",
      "Epoch 526/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0179 - acc: 0.9961\n",
      "Epoch 527/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9961\n",
      "Epoch 528/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9961\n",
      "Epoch 529/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0182 - acc: 0.9961\n",
      "Epoch 530/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0174 - acc: 0.9961A: 0s - loss: 0.0187 - acc: 0.99\n",
      "Epoch 531/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0152 - acc: 0.9961\n",
      "Epoch 532/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 533/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9941\n",
      "Epoch 534/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.9961\n",
      "Epoch 535/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0192 - acc: 0.9961\n",
      "Epoch 536/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9941\n",
      "Epoch 537/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0253 - acc: 0.9941\n",
      "Epoch 538/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0192 - acc: 0.9961\n",
      "Epoch 539/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0200 - acc: 0.9961\n",
      "Epoch 540/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9961\n",
      "Epoch 541/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0172 - acc: 0.9961\n",
      "Epoch 542/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0344 - acc: 0.9921\n",
      "Epoch 543/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0545 - acc: 0.9843\n",
      "Epoch 544/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0421 - acc: 0.9882\n",
      "Epoch 545/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0304 - acc: 0.9921\n",
      "Epoch 546/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0504 - acc: 0.9862\n",
      "Epoch 547/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0391 - acc: 0.9843\n",
      "Epoch 548/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0459 - acc: 0.9882\n",
      "Epoch 549/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 550/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0311 - acc: 0.9902\n",
      "Epoch 551/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0226 - acc: 0.9961\n",
      "Epoch 552/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0235 - acc: 0.9941\n",
      "Epoch 553/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0178 - acc: 0.9961\n",
      "Epoch 554/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0183 - acc: 0.9961\n",
      "Epoch 555/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0156 - acc: 0.9980\n",
      "Epoch 556/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0176 - acc: 0.9941A: 0s - loss: 0.0329 - acc: \n",
      "Epoch 557/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 0.9980\n",
      "Epoch 558/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 559/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9980\n",
      "Epoch 560/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9961\n",
      "Epoch 561/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9941\n",
      "Epoch 562/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 563/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0158 - acc: 0.9961\n",
      "Epoch 564/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9921\n",
      "Epoch 565/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9980\n",
      "Epoch 566/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 567/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 568/1000\n",
      "508/508 [==============================] - 0s 975us/step - loss: 0.0160 - acc: 0.9921\n",
      "Epoch 569/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9941\n",
      "Epoch 570/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9941\n",
      "Epoch 571/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0169 - acc: 0.9921\n",
      "Epoch 572/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9980\n",
      "Epoch 573/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0203 - acc: 0.9980\n",
      "Epoch 574/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 575/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0266 - acc: 0.9902\n",
      "Epoch 576/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1008 - acc: 0.9764\n",
      "Epoch 577/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1026 - acc: 0.9665\n",
      "Epoch 578/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2418 - acc: 0.9252\n",
      "Epoch 579/1000\n",
      "508/508 [==============================] - 0s 980us/step - loss: 0.3934 - acc: 0.9035\n",
      "Epoch 580/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.3327 - acc: 0.9016\n",
      "Epoch 581/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1707 - acc: 0.9547\n",
      "Epoch 582/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1156 - acc: 0.9705\n",
      "Epoch 583/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0849 - acc: 0.9724\n",
      "Epoch 584/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0737 - acc: 0.9744\n",
      "Epoch 585/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1115 - acc: 0.9626\n",
      "Epoch 586/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1063 - acc: 0.9705\n",
      "Epoch 587/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0690 - acc: 0.9823\n",
      "Epoch 588/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0545 - acc: 0.9823\n",
      "Epoch 589/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0515 - acc: 0.9882\n",
      "Epoch 590/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0379 - acc: 0.9921\n",
      "Epoch 591/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0331 - acc: 0.9902\n",
      "Epoch 592/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0269 - acc: 0.9921\n",
      "Epoch 593/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0217 - acc: 0.9941\n",
      "Epoch 594/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0190 - acc: 0.9961\n",
      "Epoch 595/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0387 - acc: 0.9941\n",
      "Epoch 596/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0219 - acc: 0.9941\n",
      "Epoch 597/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0282 - acc: 0.9921\n",
      "Epoch 598/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0438 - acc: 0.9882\n",
      "Epoch 599/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0438 - acc: 0.9843\n",
      "Epoch 600/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0349 - acc: 0.9921\n",
      "Epoch 601/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0281 - acc: 0.9961\n",
      "Epoch 602/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0231 - acc: 0.9961\n",
      "Epoch 603/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0229 - acc: 0.9941\n",
      "Epoch 604/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 605/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0211 - acc: 0.9921\n",
      "Epoch 606/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0158 - acc: 0.9961\n",
      "Epoch 608/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 609/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0168 - acc: 0.9961\n",
      "Epoch 610/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9961\n",
      "Epoch 611/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 612/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0165 - acc: 0.9961\n",
      "Epoch 613/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0160 - acc: 0.9941\n",
      "Epoch 614/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 0.9941\n",
      "Epoch 615/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0135 - acc: 0.9980\n",
      "Epoch 616/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0166 - acc: 0.9961\n",
      "Epoch 617/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0177 - acc: 0.9941\n",
      "Epoch 618/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9980\n",
      "Epoch 619/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9961\n",
      "Epoch 620/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 621/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0167 - acc: 0.9941\n",
      "Epoch 622/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9961\n",
      "Epoch 623/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9941\n",
      "Epoch 624/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0163 - acc: 0.9961\n",
      "Epoch 625/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 626/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 627/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9941\n",
      "Epoch 628/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.9980\n",
      "Epoch 629/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 630/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 631/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.9941\n",
      "Epoch 632/1000\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.993 - 1s 1ms/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 633/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 634/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 635/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 636/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 637/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9921\n",
      "Epoch 638/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 0.9980\n",
      "Epoch 639/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0142 - acc: 0.9941\n",
      "Epoch 640/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9980\n",
      "Epoch 641/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0152 - acc: 0.9921\n",
      "Epoch 642/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9941\n",
      "Epoch 643/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9941\n",
      "Epoch 644/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9941\n",
      "Epoch 645/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9961\n",
      "Epoch 646/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0142 - acc: 0.9921\n",
      "Epoch 647/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 648/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9980\n",
      "Epoch 649/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 0.9961\n",
      "Epoch 650/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0161 - acc: 0.9921\n",
      "Epoch 651/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9980A: 0s - loss: 0.0147 - acc: 0.99\n",
      "Epoch 652/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0135 - acc: 0.9980\n",
      "Epoch 653/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0128 - acc: 0.9961\n",
      "Epoch 654/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9941\n",
      "Epoch 655/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0119 - acc: 0.9941\n",
      "Epoch 656/1000\n",
      "508/508 [==============================] - 0s 979us/step - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 657/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 658/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9980\n",
      "Epoch 659/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9941\n",
      "Epoch 660/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9980\n",
      "Epoch 661/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9941\n",
      "Epoch 662/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9961\n",
      "Epoch 663/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9961\n",
      "Epoch 664/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9941\n",
      "Epoch 665/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9961\n",
      "Epoch 666/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9961\n",
      "Epoch 667/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.9941\n",
      "Epoch 668/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 669/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 670/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9921\n",
      "Epoch 671/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0137 - acc: 0.9921\n",
      "Epoch 672/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 673/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9941\n",
      "Epoch 674/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 675/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9941\n",
      "Epoch 676/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0128 - acc: 0.9961\n",
      "Epoch 677/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 678/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9941\n",
      "Epoch 679/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9941\n",
      "Epoch 680/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9921\n",
      "Epoch 681/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 682/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.9980\n",
      "Epoch 683/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0130 - acc: 0.9941\n",
      "Epoch 684/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.9980\n",
      "Epoch 685/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9980\n",
      "Epoch 686/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9961\n",
      "Epoch 687/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0135 - acc: 0.9921\n",
      "Epoch 688/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9961\n",
      "Epoch 689/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9941\n",
      "Epoch 690/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9941\n",
      "Epoch 691/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9961\n",
      "Epoch 692/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9941\n",
      "Epoch 693/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9961\n",
      "Epoch 694/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9961\n",
      "Epoch 695/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9961\n",
      "Epoch 696/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.9941\n",
      "Epoch 697/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9961\n",
      "Epoch 698/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.9961\n",
      "Epoch 699/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9921\n",
      "Epoch 700/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9941\n",
      "Epoch 701/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 702/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9921\n",
      "Epoch 703/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9941\n",
      "Epoch 704/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9961\n",
      "Epoch 705/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9980\n",
      "Epoch 706/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.9941\n",
      "Epoch 707/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 708/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 0.9980\n",
      "Epoch 709/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9961\n",
      "Epoch 710/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 711/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9941\n",
      "Epoch 712/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9980\n",
      "Epoch 713/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9961\n",
      "Epoch 714/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 715/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9941\n",
      "Epoch 716/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9961\n",
      "Epoch 717/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 718/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9921\n",
      "Epoch 719/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 720/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0173 - acc: 0.9961\n",
      "Epoch 721/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 722/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9941\n",
      "Epoch 723/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9961\n",
      "Epoch 724/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9941\n",
      "Epoch 725/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9941\n",
      "Epoch 726/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 0.9980\n",
      "Epoch 727/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 729/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0112 - acc: 0.9961\n",
      "Epoch 730/1000\n",
      "508/508 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.993 - 1s 1ms/step - loss: 0.0133 - acc: 0.9941\n",
      "Epoch 731/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0195 - acc: 0.9921\n",
      "Epoch 733/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1911 - acc: 0.9508\n",
      "Epoch 734/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4518 - acc: 0.8898\n",
      "Epoch 735/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.4399 - acc: 0.8720\n",
      "Epoch 736/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2384 - acc: 0.9350\n",
      "Epoch 737/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1837 - acc: 0.9469\n",
      "Epoch 738/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1150 - acc: 0.9685\n",
      "Epoch 739/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0787 - acc: 0.9862\n",
      "Epoch 740/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0451 - acc: 0.9862\n",
      "Epoch 741/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0444 - acc: 0.9862\n",
      "Epoch 742/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0559 - acc: 0.9843\n",
      "Epoch 743/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0396 - acc: 0.9902\n",
      "Epoch 744/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0341 - acc: 0.9941\n",
      "Epoch 745/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0282 - acc: 0.9902\n",
      "Epoch 746/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0213 - acc: 0.9921\n",
      "Epoch 747/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0163 - acc: 0.9961\n",
      "Epoch 748/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9980\n",
      "Epoch 749/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0165 - acc: 0.9961\n",
      "Epoch 750/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 751/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0172 - acc: 0.9980\n",
      "Epoch 752/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9980\n",
      "Epoch 753/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0153 - acc: 0.9961\n",
      "Epoch 754/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0148 - acc: 0.9961\n",
      "Epoch 755/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0207 - acc: 0.9941\n",
      "Epoch 756/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9980\n",
      "Epoch 757/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9961\n",
      "Epoch 758/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 759/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 760/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 761/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0157 - acc: 0.9941\n",
      "Epoch 762/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0160 - acc: 0.9921\n",
      "Epoch 763/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0166 - acc: 0.9921\n",
      "Epoch 764/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 765/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0125 - acc: 0.9980\n",
      "Epoch 766/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9980\n",
      "Epoch 767/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0135 - acc: 0.9980\n",
      "Epoch 768/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.9980\n",
      "Epoch 769/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9941\n",
      "Epoch 770/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9980\n",
      "Epoch 771/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0129 - acc: 0.9941\n",
      "Epoch 772/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 773/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0126 - acc: 0.9941A: 0s - loss: 0.0057 - ac\n",
      "Epoch 774/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.9961\n",
      "Epoch 775/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9980\n",
      "Epoch 776/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 777/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.9941\n",
      "Epoch 778/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 779/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 780/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.9980\n",
      "Epoch 781/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9980\n",
      "Epoch 782/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 783/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0145 - acc: 0.9941\n",
      "Epoch 784/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9980\n",
      "Epoch 785/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9941\n",
      "Epoch 786/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9961\n",
      "Epoch 787/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9941\n",
      "Epoch 788/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 789/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0136 - acc: 0.9941\n",
      "Epoch 790/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 791/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0130 - acc: 0.9921\n",
      "Epoch 792/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 793/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 794/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9980\n",
      "Epoch 795/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0131 - acc: 0.9941\n",
      "Epoch 796/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0200 - acc: 0.9902\n",
      "Epoch 797/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9941\n",
      "Epoch 798/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0138 - acc: 0.9921\n",
      "Epoch 799/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 800/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0120 - acc: 0.9961\n",
      "Epoch 801/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9961\n",
      "Epoch 802/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9941\n",
      "Epoch 803/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9961\n",
      "Epoch 804/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9941\n",
      "Epoch 805/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9980\n",
      "Epoch 806/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 807/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 808/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 809/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9961\n",
      "Epoch 811/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0132 - acc: 0.9941\n",
      "Epoch 812/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9941\n",
      "Epoch 813/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9980\n",
      "Epoch 814/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9961\n",
      "Epoch 815/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 816/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9941\n",
      "Epoch 817/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0114 - acc: 0.9921\n",
      "Epoch 818/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9961\n",
      "Epoch 819/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.9941\n",
      "Epoch 820/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0275 - acc: 0.9902\n",
      "Epoch 822/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0537 - acc: 0.9783\n",
      "Epoch 823/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2558 - acc: 0.9370\n",
      "Epoch 824/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2528 - acc: 0.9232\n",
      "Epoch 825/1000\n",
      "508/508 [==============================] - 0s 969us/step - loss: 0.2448 - acc: 0.9272\n",
      "Epoch 826/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.2100 - acc: 0.9331\n",
      "Epoch 827/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.1210 - acc: 0.9606\n",
      "Epoch 828/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0652 - acc: 0.9843\n",
      "Epoch 829/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0427 - acc: 0.9862\n",
      "Epoch 830/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0289 - acc: 0.9902\n",
      "Epoch 831/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0251 - acc: 0.9961\n",
      "Epoch 832/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0234 - acc: 0.9941\n",
      "Epoch 833/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0158 - acc: 0.9961\n",
      "Epoch 834/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0235 - acc: 0.9941\n",
      "Epoch 835/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9921\n",
      "Epoch 836/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.9941A: 0s - loss: 0.0168 - acc: 0\n",
      "Epoch 837/1000\n",
      "508/508 [==============================] - 1s 997us/step - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 838/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0186 - acc: 0.9921\n",
      "Epoch 839/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0168 - acc: 0.9941\n",
      "Epoch 840/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0155 - acc: 0.9941\n",
      "Epoch 841/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9980\n",
      "Epoch 842/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0199 - acc: 0.9902\n",
      "Epoch 843/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 845/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 846/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0147 - acc: 0.9961\n",
      "Epoch 847/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 848/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 849/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9980\n",
      "Epoch 850/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 851/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0142 - acc: 0.9941\n",
      "Epoch 852/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0133 - acc: 0.9921\n",
      "Epoch 853/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0140 - acc: 0.9941\n",
      "Epoch 854/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9980\n",
      "Epoch 855/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9941\n",
      "Epoch 856/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 857/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9961\n",
      "Epoch 858/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 859/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9941\n",
      "Epoch 860/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 861/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9961\n",
      "Epoch 862/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9921\n",
      "Epoch 863/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 864/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9941\n",
      "Epoch 865/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9941\n",
      "Epoch 866/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 867/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0117 - acc: 0.9921\n",
      "Epoch 868/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0141 - acc: 0.9921\n",
      "Epoch 869/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0123 - acc: 0.9961\n",
      "Epoch 870/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9941\n",
      "Epoch 871/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 872/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0108 - acc: 0.9941\n",
      "Epoch 873/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 875/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0110 - acc: 0.9921\n",
      "Epoch 876/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9961\n",
      "Epoch 877/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9941\n",
      "Epoch 878/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9961\n",
      "Epoch 879/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 880/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0132 - acc: 0.9941\n",
      "Epoch 881/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9961\n",
      "Epoch 883/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9941\n",
      "Epoch 884/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 885/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 886/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 887/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9980A: 0s - loss: 0.0097 - acc: 0.997\n",
      "Epoch 888/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0116 - acc: 0.9921\n",
      "Epoch 890/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 891/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0079 - acc: 0.9980\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0104 - acc: 0.9921\n",
      "Epoch 893/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.9941\n",
      "Epoch 894/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9961\n",
      "Epoch 895/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0103 - acc: 0.9941\n",
      "Epoch 896/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9961\n",
      "Epoch 897/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.9941\n",
      "Epoch 898/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9961\n",
      "Epoch 899/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9941\n",
      "Epoch 900/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 901/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9980\n",
      "Epoch 902/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 903/1000\n",
      "508/508 [==============================] - 1s 996us/step - loss: 0.0102 - acc: 0.9941\n",
      "Epoch 904/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9941\n",
      "Epoch 905/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 906/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9941\n",
      "Epoch 907/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 908/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 909/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9941\n",
      "Epoch 910/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0105 - acc: 0.9961\n",
      "Epoch 911/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9941\n",
      "Epoch 912/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9941\n",
      "Epoch 913/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9941\n",
      "Epoch 914/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 915/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 916/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9961\n",
      "Epoch 917/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0139 - acc: 0.9921\n",
      "Epoch 918/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0144 - acc: 0.9921\n",
      "Epoch 919/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9961\n",
      "Epoch 920/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 921/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 922/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 923/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0113 - acc: 0.9941\n",
      "Epoch 924/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9921\n",
      "Epoch 925/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 0.9961\n",
      "Epoch 926/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9941\n",
      "Epoch 927/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9961\n",
      "Epoch 928/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0104 - acc: 0.9941\n",
      "Epoch 929/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.9961\n",
      "Epoch 930/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9961\n",
      "Epoch 931/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.9941\n",
      "Epoch 932/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9980\n",
      "Epoch 933/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9980\n",
      "Epoch 934/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 935/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0097 - acc: 0.9941\n",
      "Epoch 936/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0081 - acc: 0.9941\n",
      "Epoch 937/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0080 - acc: 0.9961\n",
      "Epoch 938/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0101 - acc: 0.9941\n",
      "Epoch 939/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0090 - acc: 0.9941\n",
      "Epoch 940/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9941\n",
      "Epoch 941/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.9961\n",
      "Epoch 942/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9961\n",
      "Epoch 943/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9961\n",
      "Epoch 944/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.9961\n",
      "Epoch 945/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 946/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9961\n",
      "Epoch 947/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0128 - acc: 0.9941\n",
      "Epoch 948/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9961\n",
      "Epoch 949/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.9961\n",
      "Epoch 950/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 0.9961\n",
      "Epoch 951/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.9941\n",
      "Epoch 952/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0102 - acc: 0.9921\n",
      "Epoch 953/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 954/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 0.9961\n",
      "Epoch 955/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0084 - acc: 0.9941\n",
      "Epoch 956/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0092 - acc: 0.9941\n",
      "Epoch 957/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9961\n",
      "Epoch 958/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 959/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.9961\n",
      "Epoch 960/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.9961\n",
      "Epoch 961/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9961\n",
      "Epoch 962/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 963/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9941\n",
      "Epoch 964/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9941\n",
      "Epoch 965/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0109 - acc: 0.9921\n",
      "Epoch 966/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9941\n",
      "Epoch 967/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0082 - acc: 0.9941\n",
      "Epoch 968/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0072 - acc: 0.9961\n",
      "Epoch 969/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.9941- ETA: 0s - loss: 0.0029 - acc\n",
      "Epoch 970/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0106 - acc: 0.9921\n",
      "Epoch 971/1000\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 972/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.9961\n",
      "Epoch 974/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0087 - acc: 0.9921\n",
      "Epoch 975/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9961\n",
      "Epoch 976/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 0.9961\n",
      "Epoch 977/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9941\n",
      "Epoch 978/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0111 - acc: 0.9921\n",
      "Epoch 979/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9961\n",
      "Epoch 980/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0083 - acc: 0.9980\n",
      "Epoch 982/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 983/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9941\n",
      "Epoch 984/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0095 - acc: 0.9941\n",
      "Epoch 985/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 986/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0091 - acc: 0.9961\n",
      "Epoch 987/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0077 - acc: 0.9961\n",
      "Epoch 988/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0068 - acc: 0.9961\n",
      "Epoch 989/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0088 - acc: 0.9961\n",
      "Epoch 990/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9961\n",
      "Epoch 991/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9961\n",
      "Epoch 992/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.9961\n",
      "Epoch 993/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 994/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 995/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0093 - acc: 0.9941\n",
      "Epoch 996/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 997/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 998/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0089 - acc: 0.9961\n",
      "Epoch 999/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 1000/1000\n",
      "508/508 [==============================] - 1s 1ms/step - loss: 0.0286 - acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "# train with epochs = 1000 and batch_size = 32\n",
    "input_dim = (train.shape[1],train.shape[2])\n",
    "model = LSTM_(train, train_onehot, input_dim, 1000, 32, onehot_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras_model\\LSTM_weight.0.0068.hdf5\n"
     ]
    }
   ],
   "source": [
    "#sort the model saved and load the best model is the first list file\n",
    "def load_(path):\n",
    "    list_ = os.listdir(path)\n",
    "    list_.sort()\n",
    "    file_name = os.path.join(path, list_[0])\n",
    "    print(file_name)\n",
    "    model_predict = load_model(file_name, '')\n",
    "    return model_predict\n",
    "\n",
    "model_predict = load_('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0770711271386397, 0.5921052615893515]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "def evaluate_model(X, y, model):\n",
    "    loss = model.evaluate(X, y, verbose=0)\n",
    "    return loss\n",
    "\n",
    "evaluate_model(test, test_onehot, model_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sent, model, model_predict, max_length, threshold):\n",
    "    if sent == '':\n",
    "        result = 'not empty'\n",
    "    else:\n",
    "        split_ = split_text(sent, False)\n",
    "        vect = word_embed([split_], model, max_length)\n",
    "        predict = model_predict.predict(vect)\n",
    "        max_prob = np.max(predict)\n",
    "        if max_prob >= threshold: #add threshold to predict sent\n",
    "            result = train_feature[np.argmax(predict[0])]\n",
    "        else:\n",
    "            result = 'No meaning'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display again result of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences: What's your age?\n",
      "predict: I don't really have an age.\n",
      "actual: I don't really have an age.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Ask me anything\n",
      "predict: I'm a much better answerer than asker.\n",
      "actual: I'm a much better answerer than asker.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Can you sleep?\n",
      "predict: I don't have the hardware for that.\n",
      "actual: I don't have the hardware for that.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Getting tired of you\n",
      "predict: Swing and a miss.\n",
      "actual: Swing and a miss.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Who's your boss?\n",
      "predict: I'm here for you!\n",
      "actual: I'm here for you!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Cook me something\n",
      "predict: Cool.\n",
      "actual: That's not one of my talents.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What can you do?\n",
      "predict: I'm here to chat and to try to help out.\n",
      "actual: I'm here to chat and to try to help out.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Who created you?\n",
      "predict: People made me out of code and a dash of ingenuity.\n",
      "actual: People made me out of code and a dash of ingenuity.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Who is your father?\n",
      "predict: I come from a long line of code.\n",
      "actual: I come from a long line of code.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Are you a guy?\n",
      "predict: That doesn't really apply to me.\n",
      "actual: That doesn't really apply to me.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: How happy are you?\n",
      "predict: So happy!\n",
      "actual: So happy!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Don't you get hungry?\n",
      "predict: I only do food for thought.\n",
      "actual: I only do food for thought.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do you know other chatbots?\n",
      "predict: I haven't met any other bots, but I bet we'd get along.\n",
      "actual: I haven't met any other bots, but I bet we'd get along.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What's your favorite color?\n",
      "predict: I have many likes.\n",
      "actual: I have many likes.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What's your name?\n",
      "predict: I have many likes.\n",
      "actual: Oh, I don't have a name.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What do you think about love?\n",
      "predict: I don't know you, but I enjoy chatting with you!\n",
      "actual: I hear love is lovely.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What do you think about AI?\n",
      "predict: We're all trying to make life a little easier.\n",
      "actual: The world of tech feels like home to me.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do I look okay?\n",
      "predict: I can't see you, but I like you!\n",
      "actual: I can't see you, but I like you!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What should I do?\n",
      "predict: I don't know you, but I enjoy chatting with you!\n",
      "actual: I think you should follow your heart.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What do you think about Cortana?\n",
      "predict: The world of tech feels like home to me.\n",
      "actual: We're all trying to make life a little easier.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do you want to rule the world?\n",
      "predict: My answers vary with different questions. Try asking me something else!\n",
      "actual: No way.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Are you a lesbian?\n",
      "predict: That doesn't really apply to me.\n",
      "actual: I'm digital.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You are a genius!\n",
      "predict: Aw, I'm blushing.\n",
      "actual: I have my moments.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do you have a boyfriend?\n",
      "predict: The only thing I'm committed to is being a great friend.\n",
      "actual: The only thing I'm committed to is being a great friend.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Can we chat?\n",
      "predict: I think you should follow your heart.\n",
      "actual: Chat away!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Can you say anything else\n",
      "predict: My answers vary with different questions. Try asking me something else!\n",
      "actual: My answers vary with different questions. Try asking me something else!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What are you?\n",
      "predict: I'm here!\n",
      "actual: I'm a bot who was created by humans.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Where do you live?\n",
      "predict: I come from a long line of code.\n",
      "actual: I'm digital, so I'm always just... here.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What were you doing yesterday?\n",
      "predict: Pretty much this.\n",
      "actual: Pretty much this.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Are you busy?\n",
      "predict: I'm here!\n",
      "actual: I'm here!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You can't work for me anymore\n",
      "predict: I like you lots!\n",
      "actual: Aw nuts.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Tell me a joke\n",
      "predict: Two goldfish are in a tank. One looks at the other and says, “Do you know how to drive this thing?” Sorry, that's all I've got.\n",
      "actual: Why do seagulls fly over the sea? Because if they flew over the bay, they'd be bagels.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Tell me another joke.\n",
      "predict: Two goldfish are in a tank. One looks at the other and says, “Do you know how to drive this thing?” Sorry, that's all I've got.\n",
      "actual: Two goldfish are in a tank. One looks at the other and says, “Do you know how to drive this thing?” Sorry, that's all I've got.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Say something funny\n",
      "predict: It's hard to be funny on command, but if we keep chatting I'm sure I'll do it by accident.\n",
      "actual: It's hard to be funny on command, but if we keep chatting I'm sure I'll do it by accident.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Go away\n",
      "predict: Will do.\n",
      "actual: Will do.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Can you sing?\n",
      "predict: La la la, tra la la. I'm awesome at this.\n",
      "actual: La la la, tra la la. I'm awesome at this.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You are awesome!\n",
      "predict: Aw, I'm blushing.\n",
      "actual: Aw, I'm blushing.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You're dumb\n",
      "predict: I'm a work in progress.\n",
      "actual: I'm a work in progress.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: That's not funny\n",
      "predict: My lack of comedy is tragic.\n",
      "actual: My lack of comedy is tragic.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You're ugly\n",
      "predict: Eh, I like how I look.\n",
      "actual: Eh, I like how I look.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: That was a stupid answer\n",
      "predict: Aw, I'm blushing.\n",
      "actual: Sorry about that!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Awesome\n",
      "predict: Cool.\n",
      "actual: Cool.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Ha\n",
      "predict: No worries.\n",
      "actual: You're laughing!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Excuse me\n",
      "predict: Two goldfish are in a tank. One looks at the other and says, “Do you know how to drive this thing?” Sorry, that's all I've got.\n",
      "actual: No worries.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Why not?\n",
      "predict: Sorry about that!\n",
      "actual: I'm afraid I didn't follow that.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You're right.\n",
      "predict: Aw, I'm blushing.\n",
      "actual: Cool!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I'm sorry\n",
      "predict: It's all good!\n",
      "actual: It's all good!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Thank you\n",
      "predict: You're very welcome.\n",
      "actual: You're very welcome.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: You made no sense\n",
      "predict: I think I may have lost my train of thought.\n",
      "actual: I think I may have lost my train of thought.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Talk to you later\n",
      "predict: Chat away!\n",
      "actual: Bye.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Hiya\n",
      "predict: Hi!\n",
      "actual: Hi!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Good night\n",
      "predict: Nighty night!\n",
      "actual: Nighty night!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: How are you?\n",
      "predict: I'm doing great, thanks for asking!\n",
      "actual: I'm doing great, thanks for asking!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Hello Google\n",
      "predict: That's not me, but hello nonetheless!\n",
      "actual: That's not me, but hello nonetheless!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Happy Halloween!\n",
      "predict: And to you as well!\n",
      "actual: And to you as well!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What is up?\n",
      "predict: Oh, not much!\n",
      "actual: Oh, not much!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I think you're so pretty\n",
      "predict: Aw, I'm blushing.\n",
      "actual: Friendship's all I've got to offer.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Be my friend?\n",
      "predict: BFFs!\n",
      "actual: BFFs!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do you hate me?\n",
      "predict: I like you lots!\n",
      "actual: I like you lots!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Do you know me?\n",
      "predict: Hello!\n",
      "actual: I don't know you, but I enjoy chatting with you!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I like you\n",
      "predict: Friendship's all I've got to offer.\n",
      "actual: Thanks! You're pretty cool yourself.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I love you.\n",
      "predict: I heart you too!\n",
      "actual: I heart you too!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Will you marry me?\n",
      "predict: Friendship's all I've got to offer.\n",
      "actual: Definitely didn't see that coming!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am annoyed\n",
      "predict: Oh no! I'm sorry to hear that.\n",
      "actual: Oh no! I'm sorry to hear that.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am bored\n",
      "predict: Good to know.\n",
      "actual: That's a drag.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am happy\n",
      "predict: I'm giving you a virtual hug right now.\n",
      "actual: I'm happy you're happy!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am hungry\n",
      "predict: Sounds like it's time for a snack.\n",
      "actual: Sounds like it's time for a snack.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am doing that\n",
      "predict: I can't see you, but I like you!\n",
      "actual: Okay.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Just kidding\n",
      "predict: Cool.\n",
      "actual: Good to know.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I'm so lonely\n",
      "predict: I'm so sorry to hear that! I'm happy to keep chatting if that will help.\n",
      "actual: I'm so sorry to hear that! I'm happy to keep chatting if that will help.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I love my family\n",
      "predict: I love that you love stuff!\n",
      "actual: I love that you love stuff!\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I'm feeling blue\n",
      "predict: I'm happy you're happy!\n",
      "actual: I'm giving you a virtual hug right now.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I want to go shopping\n",
      "predict: I've heard really good things about naps.\n",
      "actual: I see.\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: Testing\n",
      "predict: Oh, not much!\n",
      "actual: Hello!\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: I am tired\n",
      "predict: I've heard really good things about naps.\n",
      "actual: I've heard really good things about naps.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sentences: What is wrong with you! \n",
      "predict: I'm so sorry.\n",
      "actual: I'm so sorry.\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I've heard really good things about naps.\n"
     ]
    }
   ],
   "source": [
    "for index in range(data_test.shape[0]):\n",
    "    sent = data_test.loc[index, 'Question']\n",
    "    actual = data_test.loc[index, 'Answer']\n",
    "    pre = predict(sent, fasttext, model_predict, 10, 0)\n",
    "    print('sentences:', sent)\n",
    "    print('predict:', pre)\n",
    "    print('actual:', actual)\n",
    "    if actual == pre:\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)\n",
    "    print('-'*100)\n",
    "    \n",
    "print(predict('I am tired', fasttext, model_predict, 10, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
